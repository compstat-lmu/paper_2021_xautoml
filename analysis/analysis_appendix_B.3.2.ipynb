{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Appendix B.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 3.6.3\"\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'ggpubr' was built under R version 3.6.3\""
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(ggpubr)\n",
    "source(\"helper.r\")\n",
    "theme_set(theme_pubr(legend = \"none\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder, with folders for dataset results\n",
    "path = \"../data/mlp_eval/\"\n",
    "datasets = list.files(path)\n",
    "\n",
    "# create list with one list containing one dataframe per dataset\n",
    "data.list = lapply(datasets, function(data){\n",
    "  \n",
    "  data.path = paste0(path, data, \"/\")\n",
    "  objectives = list.files(data.path)\n",
    "  \n",
    "  for(i in 1:length(objectives)){\n",
    " \n",
    "    res = readRDS(paste0(data.path, objectives[i]))\n",
    "    df.sub = res$result[[1]]$eval\n",
    "    df.sub$objective = res$objective\n",
    "    \n",
    "    if(i == 1) df = df.sub\n",
    "    else df = rbind(df, df.sub)\n",
    "  }\n",
    "  \n",
    "  return(df)\n",
    "})\n",
    "names(data.list) = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>dataset</th><th scope=col>mean</th><th scope=col>sd</th><th scope=col>feature</th><th scope=col>mean.1</th><th scope=col>feature.1</th><th scope=col>mean.2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>adult                                 </td><td>  29.679880                           </td><td> 38.33041                             </td><td>max_units                             </td><td>71.747824                             </td><td>momentum                              </td><td> -36.469499                           </td></tr>\n",
       "\t<tr><td>airlines                              </td><td>-106.195752                           </td><td>145.74535                             </td><td>num_layers                            </td><td>26.625847                             </td><td>momentum                              </td><td>-367.464468                           </td></tr>\n",
       "\t<tr><td>albert                                </td><td> -16.853957                           </td><td>104.21805                             </td><td>num_layers                            </td><td>56.175150                             </td><td>momentum                              </td><td>-186.664545                           </td></tr>\n",
       "\t<tr><td>Amazon_employee_access                </td><td>  10.654426                           </td><td> 56.21902                             </td><td>learning_rate                         </td><td>66.433154                             </td><td>max_units                             </td><td> -67.650299                           </td></tr>\n",
       "\t<tr><td>APSFailure                            </td><td>  34.585467                           </td><td> 28.27636                             </td><td>learning_rate                         </td><td>55.607079                             </td><td>max_dropout                           </td><td>  -2.783801                           </td></tr>\n",
       "\t<tr><td>Australian                            </td><td>  21.751856                           </td><td> 33.83374                             </td><td>num_layers                            </td><td>62.527800                             </td><td>weight_decay                          </td><td> -14.817099                           </td></tr>\n",
       "\t<tr><td>bank-marketing                        </td><td> -40.949433                           </td><td> 90.90373                             </td><td>learning_rate                         </td><td>63.620560                             </td><td>max_dropout                           </td><td>-155.651798                           </td></tr>\n",
       "\t<tr><td>blood-transfusion-service-center      </td><td> -42.285216                           </td><td> 82.98105                             </td><td>batch_size                            </td><td> 5.147775                             </td><td>momentum                              </td><td> -93.566774                           </td></tr>\n",
       "\t<tr><td>car                                   </td><td>  12.064988                           </td><td> 54.29283                             </td><td>momentum                              </td><td>57.175694                             </td><td>weight_decay                          </td><td> -41.506564                           </td></tr>\n",
       "\t<tr><td>christine                             </td><td>  13.796595                           </td><td> 39.42916                             </td><td>momentum                              </td><td>52.701087                             </td><td>num_layers                            </td><td> -10.653824                           </td></tr>\n",
       "\t<tr><td>cnae-9                                </td><td>  47.578120                           </td><td> 39.35108                             </td><td>momentum                              </td><td>86.763158                             </td><td>num_layers                            </td><td>   3.105533                           </td></tr>\n",
       "\t<tr><td>connect-4                             </td><td> -50.006849                           </td><td> 80.32038                             </td><td>batch_size                            </td><td>-7.191944                             </td><td>weight_decay                          </td><td>-184.143420                           </td></tr>\n",
       "\t<tr><td>covertype                             </td><td> -14.918834                           </td><td>119.74058                             </td><td>batch_size                            </td><td>66.822193                             </td><td>max_dropout                           </td><td>-263.299520                           </td></tr>\n",
       "\t<tr><td>credit-g                              </td><td>  76.485193                           </td><td> 20.58726                             </td><td>momentum                              </td><td>91.590185                             </td><td>num_layers                            </td><td>  47.063180                           </td></tr>\n",
       "\t<tr><td>dionis                                </td><td> -68.589965                           </td><td>160.65894                             </td><td>num_layers                            </td><td>57.786697                             </td><td>batch_size                            </td><td>-240.202287                           </td></tr>\n",
       "\t<tr><td>fabert                                </td><td>  37.351555                           </td><td> 52.75795                             </td><td>max_units                             </td><td>87.154069                             </td><td>max_dropout                           </td><td> -59.641283                           </td></tr>\n",
       "\t<tr><td>Fashion-MNIST                         </td><td>  16.171057                           </td><td> 54.76955                             </td><td>num_layers                            </td><td>78.479918                             </td><td>max_dropout                           </td><td> -67.430321                           </td></tr>\n",
       "\t<tr><td>helena                                </td><td>  -5.933381                           </td><td> 72.44769                             </td><td>max_units                             </td><td>58.711210                             </td><td>batch_size                            </td><td> -82.093803                           </td></tr>\n",
       "\t<tr><td>higgs                                 </td><td> -31.637670                           </td><td>107.52329                             </td><td>num_layers                            </td><td>69.785246                             </td><td>weight_decay                          </td><td>-143.583235                           </td></tr>\n",
       "\t<tr><td>jannis                                </td><td> -18.126217                           </td><td>121.34335                             </td><td>num_layers                            </td><td>53.505144                             </td><td>momentum                              </td><td>-100.069952                           </td></tr>\n",
       "\t<tr><td>jasmine                               </td><td>   9.166826                           </td><td> 82.77850                             </td><td>max_units                             </td><td>79.630258                             </td><td>batch_size                            </td><td>-138.477867                           </td></tr>\n",
       "\t<tr><td>jungle_chess_2pcs_raw_endgame_complete</td><td>-141.086838                           </td><td>113.26869                             </td><td>max_dropout                           </td><td> 6.938300                             </td><td>momentum                              </td><td>-220.746747                           </td></tr>\n",
       "\t<tr><td>kc1                                   </td><td> -42.952736                           </td><td>120.78008                             </td><td>momentum                              </td><td>37.990847                             </td><td>max_dropout                           </td><td>-209.656098                           </td></tr>\n",
       "\t<tr><td>KDDCup09_appetency                    </td><td> -61.755402                           </td><td>139.86977                             </td><td>batch_size                            </td><td>62.943361                             </td><td>weight_decay                          </td><td>-255.217180                           </td></tr>\n",
       "\t<tr><td>kr-vs-kp                              </td><td>  22.148522                           </td><td> 68.29771                             </td><td>max_units                             </td><td>71.323303                             </td><td>momentum                              </td><td>-103.641310                           </td></tr>\n",
       "\t<tr><td>mfeat-factors                         </td><td>  29.383489                           </td><td> 55.87572                             </td><td>max_units                             </td><td>90.750863                             </td><td>batch_size                            </td><td> -32.560154                           </td></tr>\n",
       "\t<tr><td>MiniBooNE                             </td><td>  -3.731130                           </td><td> 55.75734                             </td><td>max_units                             </td><td>30.070540                             </td><td>weight_decay                          </td><td> -78.769806                           </td></tr>\n",
       "\t<tr><td>nomao                                 </td><td>  23.747995                           </td><td> 29.80966                             </td><td>num_layers                            </td><td>44.744718                             </td><td>batch_size                            </td><td> -12.318543                           </td></tr>\n",
       "\t<tr><td>numerai28.6                           </td><td>  33.834457                           </td><td>105.03341                             </td><td>momentum                              </td><td>69.195337                             </td><td>learning_rate                         </td><td> -21.105941                           </td></tr>\n",
       "\t<tr><td>phoneme                               </td><td> -12.651583                           </td><td>103.27893                             </td><td>max_units                             </td><td>52.792246                             </td><td>momentum                              </td><td>-210.500801                           </td></tr>\n",
       "\t<tr><td>segment                               </td><td>   6.778623                           </td><td> 73.54089                             </td><td>max_units                             </td><td>62.629258                             </td><td>max_dropout                           </td><td> -73.439882                           </td></tr>\n",
       "\t<tr><td>shuttle                               </td><td>  45.016746                           </td><td> 25.78479                             </td><td>max_units                             </td><td>82.122520                             </td><td>max_dropout                           </td><td>   9.160773                           </td></tr>\n",
       "\t<tr><td>sylvine                               </td><td>   6.134005                           </td><td> 97.59869                             </td><td>max_units                             </td><td>68.707990                             </td><td>batch_size                            </td><td> -67.315875                           </td></tr>\n",
       "\t<tr><td>vehicle                               </td><td>  -2.748126                           </td><td> 78.51806                             </td><td>max_units                             </td><td>62.696446                             </td><td>momentum                              </td><td>-100.502992                           </td></tr>\n",
       "\t<tr><td>volkert                               </td><td> -18.517867                           </td><td> 93.61259                             </td><td>num_layers                            </td><td>63.814010                             </td><td>max_dropout                           </td><td>-193.206557                           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " dataset & mean & sd & feature & mean.1 & feature.1 & mean.2\\\\\n",
       "\\hline\n",
       "\t adult                                  &   29.679880                            &  38.33041                              & max\\_units                            & 71.747824                              & momentum                               &  -36.469499                           \\\\\n",
       "\t airlines                               & -106.195752                            & 145.74535                              & num\\_layers                           & 26.625847                              & momentum                               & -367.464468                           \\\\\n",
       "\t albert                                 &  -16.853957                            & 104.21805                              & num\\_layers                           & 56.175150                              & momentum                               & -186.664545                           \\\\\n",
       "\t Amazon\\_employee\\_access                 &   10.654426                                &  56.21902                                  & learning\\_rate                            & 66.433154                                  & max\\_units                                &  -67.650299                               \\\\\n",
       "\t APSFailure                             &   34.585467                            &  28.27636                              & learning\\_rate                        & 55.607079                              & max\\_dropout                          &   -2.783801                           \\\\\n",
       "\t Australian                             &   21.751856                            &  33.83374                              & num\\_layers                           & 62.527800                              & weight\\_decay                         &  -14.817099                           \\\\\n",
       "\t bank-marketing                         &  -40.949433                            &  90.90373                              & learning\\_rate                        & 63.620560                              & max\\_dropout                          & -155.651798                           \\\\\n",
       "\t blood-transfusion-service-center       &  -42.285216                            &  82.98105                              & batch\\_size                           &  5.147775                              & momentum                               &  -93.566774                           \\\\\n",
       "\t car                                    &   12.064988                            &  54.29283                              & momentum                               & 57.175694                              & weight\\_decay                         &  -41.506564                           \\\\\n",
       "\t christine                              &   13.796595                            &  39.42916                              & momentum                               & 52.701087                              & num\\_layers                           &  -10.653824                           \\\\\n",
       "\t cnae-9                                 &   47.578120                            &  39.35108                              & momentum                               & 86.763158                              & num\\_layers                           &    3.105533                           \\\\\n",
       "\t connect-4                              &  -50.006849                            &  80.32038                              & batch\\_size                           & -7.191944                              & weight\\_decay                         & -184.143420                           \\\\\n",
       "\t covertype                              &  -14.918834                            & 119.74058                              & batch\\_size                           & 66.822193                              & max\\_dropout                          & -263.299520                           \\\\\n",
       "\t credit-g                               &   76.485193                            &  20.58726                              & momentum                               & 91.590185                              & num\\_layers                           &   47.063180                           \\\\\n",
       "\t dionis                                 &  -68.589965                            & 160.65894                              & num\\_layers                           & 57.786697                              & batch\\_size                           & -240.202287                           \\\\\n",
       "\t fabert                                 &   37.351555                            &  52.75795                              & max\\_units                            & 87.154069                              & max\\_dropout                          &  -59.641283                           \\\\\n",
       "\t Fashion-MNIST                          &   16.171057                            &  54.76955                              & num\\_layers                           & 78.479918                              & max\\_dropout                          &  -67.430321                           \\\\\n",
       "\t helena                                 &   -5.933381                            &  72.44769                              & max\\_units                            & 58.711210                              & batch\\_size                           &  -82.093803                           \\\\\n",
       "\t higgs                                  &  -31.637670                            & 107.52329                              & num\\_layers                           & 69.785246                              & weight\\_decay                         & -143.583235                           \\\\\n",
       "\t jannis                                 &  -18.126217                            & 121.34335                              & num\\_layers                           & 53.505144                              & momentum                               & -100.069952                           \\\\\n",
       "\t jasmine                                &    9.166826                            &  82.77850                              & max\\_units                            & 79.630258                              & batch\\_size                           & -138.477867                           \\\\\n",
       "\t jungle\\_chess\\_2pcs\\_raw\\_endgame\\_complete & -141.086838                                      & 113.26869                                        & max\\_dropout                                    &  6.938300                                        & momentum                                         & -220.746747                                     \\\\\n",
       "\t kc1                                    &  -42.952736                            & 120.78008                              & momentum                               & 37.990847                              & max\\_dropout                          & -209.656098                           \\\\\n",
       "\t KDDCup09\\_appetency                     &  -61.755402                              & 139.86977                                & batch\\_size                             & 62.943361                                & weight\\_decay                           & -255.217180                             \\\\\n",
       "\t kr-vs-kp                               &   22.148522                            &  68.29771                              & max\\_units                            & 71.323303                              & momentum                               & -103.641310                           \\\\\n",
       "\t mfeat-factors                          &   29.383489                            &  55.87572                              & max\\_units                            & 90.750863                              & batch\\_size                           &  -32.560154                           \\\\\n",
       "\t MiniBooNE                              &   -3.731130                            &  55.75734                              & max\\_units                            & 30.070540                              & weight\\_decay                         &  -78.769806                           \\\\\n",
       "\t nomao                                  &   23.747995                            &  29.80966                              & num\\_layers                           & 44.744718                              & batch\\_size                           &  -12.318543                           \\\\\n",
       "\t numerai28.6                            &   33.834457                            & 105.03341                              & momentum                               & 69.195337                              & learning\\_rate                        &  -21.105941                           \\\\\n",
       "\t phoneme                                &  -12.651583                            & 103.27893                              & max\\_units                            & 52.792246                              & momentum                               & -210.500801                           \\\\\n",
       "\t segment                                &    6.778623                            &  73.54089                              & max\\_units                            & 62.629258                              & max\\_dropout                          &  -73.439882                           \\\\\n",
       "\t shuttle                                &   45.016746                            &  25.78479                              & max\\_units                            & 82.122520                              & max\\_dropout                          &    9.160773                           \\\\\n",
       "\t sylvine                                &    6.134005                            &  97.59869                              & max\\_units                            & 68.707990                              & batch\\_size                           &  -67.315875                           \\\\\n",
       "\t vehicle                                &   -2.748126                            &  78.51806                              & max\\_units                            & 62.696446                              & momentum                               & -100.502992                           \\\\\n",
       "\t volkert                                &  -18.517867                            &  93.61259                              & num\\_layers                           & 63.814010                              & max\\_dropout                          & -193.206557                           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| dataset | mean | sd | feature | mean.1 | feature.1 | mean.2 |\n",
       "|---|---|---|---|---|---|---|\n",
       "| adult                                  |   29.679880                            |  38.33041                              | max_units                              | 71.747824                              | momentum                               |  -36.469499                            |\n",
       "| airlines                               | -106.195752                            | 145.74535                              | num_layers                             | 26.625847                              | momentum                               | -367.464468                            |\n",
       "| albert                                 |  -16.853957                            | 104.21805                              | num_layers                             | 56.175150                              | momentum                               | -186.664545                            |\n",
       "| Amazon_employee_access                 |   10.654426                            |  56.21902                              | learning_rate                          | 66.433154                              | max_units                              |  -67.650299                            |\n",
       "| APSFailure                             |   34.585467                            |  28.27636                              | learning_rate                          | 55.607079                              | max_dropout                            |   -2.783801                            |\n",
       "| Australian                             |   21.751856                            |  33.83374                              | num_layers                             | 62.527800                              | weight_decay                           |  -14.817099                            |\n",
       "| bank-marketing                         |  -40.949433                            |  90.90373                              | learning_rate                          | 63.620560                              | max_dropout                            | -155.651798                            |\n",
       "| blood-transfusion-service-center       |  -42.285216                            |  82.98105                              | batch_size                             |  5.147775                              | momentum                               |  -93.566774                            |\n",
       "| car                                    |   12.064988                            |  54.29283                              | momentum                               | 57.175694                              | weight_decay                           |  -41.506564                            |\n",
       "| christine                              |   13.796595                            |  39.42916                              | momentum                               | 52.701087                              | num_layers                             |  -10.653824                            |\n",
       "| cnae-9                                 |   47.578120                            |  39.35108                              | momentum                               | 86.763158                              | num_layers                             |    3.105533                            |\n",
       "| connect-4                              |  -50.006849                            |  80.32038                              | batch_size                             | -7.191944                              | weight_decay                           | -184.143420                            |\n",
       "| covertype                              |  -14.918834                            | 119.74058                              | batch_size                             | 66.822193                              | max_dropout                            | -263.299520                            |\n",
       "| credit-g                               |   76.485193                            |  20.58726                              | momentum                               | 91.590185                              | num_layers                             |   47.063180                            |\n",
       "| dionis                                 |  -68.589965                            | 160.65894                              | num_layers                             | 57.786697                              | batch_size                             | -240.202287                            |\n",
       "| fabert                                 |   37.351555                            |  52.75795                              | max_units                              | 87.154069                              | max_dropout                            |  -59.641283                            |\n",
       "| Fashion-MNIST                          |   16.171057                            |  54.76955                              | num_layers                             | 78.479918                              | max_dropout                            |  -67.430321                            |\n",
       "| helena                                 |   -5.933381                            |  72.44769                              | max_units                              | 58.711210                              | batch_size                             |  -82.093803                            |\n",
       "| higgs                                  |  -31.637670                            | 107.52329                              | num_layers                             | 69.785246                              | weight_decay                           | -143.583235                            |\n",
       "| jannis                                 |  -18.126217                            | 121.34335                              | num_layers                             | 53.505144                              | momentum                               | -100.069952                            |\n",
       "| jasmine                                |    9.166826                            |  82.77850                              | max_units                              | 79.630258                              | batch_size                             | -138.477867                            |\n",
       "| jungle_chess_2pcs_raw_endgame_complete | -141.086838                            | 113.26869                              | max_dropout                            |  6.938300                              | momentum                               | -220.746747                            |\n",
       "| kc1                                    |  -42.952736                            | 120.78008                              | momentum                               | 37.990847                              | max_dropout                            | -209.656098                            |\n",
       "| KDDCup09_appetency                     |  -61.755402                            | 139.86977                              | batch_size                             | 62.943361                              | weight_decay                           | -255.217180                            |\n",
       "| kr-vs-kp                               |   22.148522                            |  68.29771                              | max_units                              | 71.323303                              | momentum                               | -103.641310                            |\n",
       "| mfeat-factors                          |   29.383489                            |  55.87572                              | max_units                              | 90.750863                              | batch_size                             |  -32.560154                            |\n",
       "| MiniBooNE                              |   -3.731130                            |  55.75734                              | max_units                              | 30.070540                              | weight_decay                           |  -78.769806                            |\n",
       "| nomao                                  |   23.747995                            |  29.80966                              | num_layers                             | 44.744718                              | batch_size                             |  -12.318543                            |\n",
       "| numerai28.6                            |   33.834457                            | 105.03341                              | momentum                               | 69.195337                              | learning_rate                          |  -21.105941                            |\n",
       "| phoneme                                |  -12.651583                            | 103.27893                              | max_units                              | 52.792246                              | momentum                               | -210.500801                            |\n",
       "| segment                                |    6.778623                            |  73.54089                              | max_units                              | 62.629258                              | max_dropout                            |  -73.439882                            |\n",
       "| shuttle                                |   45.016746                            |  25.78479                              | max_units                              | 82.122520                              | max_dropout                            |    9.160773                            |\n",
       "| sylvine                                |    6.134005                            |  97.59869                              | max_units                              | 68.707990                              | batch_size                             |  -67.315875                            |\n",
       "| vehicle                                |   -2.748126                            |  78.51806                              | max_units                              | 62.696446                              | momentum                               | -100.502992                            |\n",
       "| volkert                                |  -18.517867                            |  93.61259                              | num_layers                             | 63.814010                              | max_dropout                            | -193.206557                            |\n",
       "\n"
      ],
      "text/plain": [
       "   dataset                                mean        sd        feature      \n",
       "1  adult                                    29.679880  38.33041 max_units    \n",
       "2  airlines                               -106.195752 145.74535 num_layers   \n",
       "3  albert                                  -16.853957 104.21805 num_layers   \n",
       "4  Amazon_employee_access                   10.654426  56.21902 learning_rate\n",
       "5  APSFailure                               34.585467  28.27636 learning_rate\n",
       "6  Australian                               21.751856  33.83374 num_layers   \n",
       "7  bank-marketing                          -40.949433  90.90373 learning_rate\n",
       "8  blood-transfusion-service-center        -42.285216  82.98105 batch_size   \n",
       "9  car                                      12.064988  54.29283 momentum     \n",
       "10 christine                                13.796595  39.42916 momentum     \n",
       "11 cnae-9                                   47.578120  39.35108 momentum     \n",
       "12 connect-4                               -50.006849  80.32038 batch_size   \n",
       "13 covertype                               -14.918834 119.74058 batch_size   \n",
       "14 credit-g                                 76.485193  20.58726 momentum     \n",
       "15 dionis                                  -68.589965 160.65894 num_layers   \n",
       "16 fabert                                   37.351555  52.75795 max_units    \n",
       "17 Fashion-MNIST                            16.171057  54.76955 num_layers   \n",
       "18 helena                                   -5.933381  72.44769 max_units    \n",
       "19 higgs                                   -31.637670 107.52329 num_layers   \n",
       "20 jannis                                  -18.126217 121.34335 num_layers   \n",
       "21 jasmine                                   9.166826  82.77850 max_units    \n",
       "22 jungle_chess_2pcs_raw_endgame_complete -141.086838 113.26869 max_dropout  \n",
       "23 kc1                                     -42.952736 120.78008 momentum     \n",
       "24 KDDCup09_appetency                      -61.755402 139.86977 batch_size   \n",
       "25 kr-vs-kp                                 22.148522  68.29771 max_units    \n",
       "26 mfeat-factors                            29.383489  55.87572 max_units    \n",
       "27 MiniBooNE                                -3.731130  55.75734 max_units    \n",
       "28 nomao                                    23.747995  29.80966 num_layers   \n",
       "29 numerai28.6                              33.834457 105.03341 momentum     \n",
       "30 phoneme                                 -12.651583 103.27893 max_units    \n",
       "31 segment                                   6.778623  73.54089 max_units    \n",
       "32 shuttle                                  45.016746  25.78479 max_units    \n",
       "33 sylvine                                   6.134005  97.59869 max_units    \n",
       "34 vehicle                                  -2.748126  78.51806 max_units    \n",
       "35 volkert                                 -18.517867  93.61259 num_layers   \n",
       "   mean.1    feature.1     mean.2     \n",
       "1  71.747824 momentum       -36.469499\n",
       "2  26.625847 momentum      -367.464468\n",
       "3  56.175150 momentum      -186.664545\n",
       "4  66.433154 max_units      -67.650299\n",
       "5  55.607079 max_dropout     -2.783801\n",
       "6  62.527800 weight_decay   -14.817099\n",
       "7  63.620560 max_dropout   -155.651798\n",
       "8   5.147775 momentum       -93.566774\n",
       "9  57.175694 weight_decay   -41.506564\n",
       "10 52.701087 num_layers     -10.653824\n",
       "11 86.763158 num_layers       3.105533\n",
       "12 -7.191944 weight_decay  -184.143420\n",
       "13 66.822193 max_dropout   -263.299520\n",
       "14 91.590185 num_layers      47.063180\n",
       "15 57.786697 batch_size    -240.202287\n",
       "16 87.154069 max_dropout    -59.641283\n",
       "17 78.479918 max_dropout    -67.430321\n",
       "18 58.711210 batch_size     -82.093803\n",
       "19 69.785246 weight_decay  -143.583235\n",
       "20 53.505144 momentum      -100.069952\n",
       "21 79.630258 batch_size    -138.477867\n",
       "22  6.938300 momentum      -220.746747\n",
       "23 37.990847 max_dropout   -209.656098\n",
       "24 62.943361 weight_decay  -255.217180\n",
       "25 71.323303 momentum      -103.641310\n",
       "26 90.750863 batch_size     -32.560154\n",
       "27 30.070540 weight_decay   -78.769806\n",
       "28 44.744718 batch_size     -12.318543\n",
       "29 69.195337 learning_rate  -21.105941\n",
       "30 52.792246 momentum      -210.500801\n",
       "31 62.629258 max_dropout    -73.439882\n",
       "32 82.122520 max_dropout      9.160773\n",
       "33 68.707990 batch_size     -67.315875\n",
       "34 62.696446 momentum      -100.502992\n",
       "35 63.814010 max_dropout   -193.206557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# analysis of confidence improvement\n",
    "df_datasets = create_table_datasets(data.list, \"SS_L2\", \"gt.diff.sd\", 7)\n",
    "df_feat_worst = as.data.frame(df_datasets %>% group_by(feature.1) %>% summarise(n()))\n",
    "df_feat_best = as.data.frame(df_datasets %>% group_by(feature) %>% summarise(n()))\n",
    "df_feat = left_join(df_feat_best, df_feat_worst, by = c(\"feature\"= \"feature.1\"))\n",
    "\n",
    "df_datasets[,c(\"mean\",\"sd\",\"mean.1\", \"mean.2\")] = df_datasets[,c(\"mean\",\"sd\",\"mean.1\", \"mean.2\")]*100\n",
    "#print(xtable(df_datasets[,-c(4,6)], digits = 0), include.rownames=FALSE)\n",
    "df_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of neg loglik improvement\n",
    "df_datasets = create_table_datasets(data.all, \"SS_L1\", \"neg_loglik.rel\", 7)\n",
    "df_feat_worst = as.data.frame(df_datasets %>% group_by(feature.1) %>% summarise(n()))\n",
    "df_feat_best = as.data.frame(df_datasets %>% group_by(feature) %>% summarise(n()))\n",
    "df_feat_loglik = left_join(df_feat_best, df_feat_worst, by = c(\"feature\"= \"feature.1\"))\n",
    "df_feat = left_join(df_feat, df_feat_loglik, by = \"feature\")\n",
    "\n",
    "df_datasets[,c(\"mean\",\"sd\",\"mean.1\", \"mean.2\")] = df_datasets[,c(\"mean\",\"sd\",\"mean.1\", \"mean.2\")]*100\n",
    "print(xtable(df_datasets[,-c(4,6)], digits = 0), include.rownames=FALSE)\n",
    "print(xtable(df_feat), include.rownames=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = do.call(\"rbind\", data.all)\n",
    "ggplot(data_combined, aes_string(x = \"objective\", y = \"gt.abs\")) + geom_boxplot(aes(fill = as.factor(depth)))  + facet_grid(. ~ feature)\n",
    "\n",
    "data_SS_L1 = data_combined[data_combined$objective==\"SS_L1\",]\n",
    "data_SS_sd = data_combined[data_combined$objective==\"SS_sd\",]\n",
    "data_SS_L1$conf.diff_sd = data_combined[data_combined$objective==\"SS_sd\",]$conf.diff\n",
    "data_SS_L1$conf.diff_L2 = data_combined[data_combined$objective==\"SS_L2\",]$conf.diff\n",
    "data_SS_L1$conf.diff_area = data_combined[data_combined$objective==\"SS_area\",]$conf.diff\n",
    "\n",
    "data_SS_L1$conf.diff.opt_sd = data_combined[data_combined$objective==\"SS_sd\",]$gt.abs\n",
    "\n",
    "for(i in 1:nrow(data_SS_L1)){\n",
    "  ranks = rank(data_SS_L1[i, c(\"conf.diff\",\"conf.diff_sd\",\"conf.diff_L2\",\"conf.diff_area\")])\n",
    "  data_SS_L1$L1_rank[i] = ranks[1]\n",
    "  data_SS_L1$sd_rank[i] = ranks[2]\n",
    "  data_SS_L1$L2_rank[i] = ranks[3]\n",
    "  data_SS_L1$area_rank[i] = ranks[4]\n",
    "}\n",
    "\n",
    "\n",
    "for(i in 1:nrow(data_SS_L1)){\n",
    "  ranks = rank(data_SS_L1[i, c(\"conf.diff\",\"conf.diff_sd\")])\n",
    "  data_SS_L1$L1_rank[i] = ranks[1]\n",
    "  data_SS_L1$sd_rank[i] = ranks[2]\n",
    "  #data_SS_L1$L2_rank[i] = ranks[3]\n",
    "  #data_SS_L1$area_rank[i] = ranks[4]\n",
    "}\n",
    "\n",
    "data_SS_L1_7 = data_SS_L1[data_SS_L1$depth==8,]\n",
    "ggplot(data = data_SS_L1_7, aes(x = sd_rank))  + geom_bar(aes(y = (..count..)/sum(..count..))) \n",
    "\n",
    "summary(data_SS_L1$conf.diff_sd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
